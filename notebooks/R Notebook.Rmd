---
title: "Multi-level Pricing Model"
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = FALSE)
```

```{r, message = FALSE, warning = FALSE}
library(rstan)
library(loo)
library(tidyverse)
library(here)
setwd(here())
```

```{r}
rstan_options(auto_write = TRUE) #cache model
options(mc.cores = parallel::detectCores()) #multiple cores for multiple chains
```

We'll be doing some 2, 3 and even 4-level models in Stan, then comparing them using the Loo package.

### The Data

```{r}
model_data <- read.csv("data/model_data.csv")
colnames(model_data) <- c("Price", "store_id", "UPC", "banner_id", "region_id")
```

The regressand is the price of an item. Regressors include the UPC of the item, the specific store, the supermarket brand, and the region.

```{r coding the data}
#level 1 n
N_obs = nrow(model_data)
#level 2 n
N_stores = length(unique(model_data$store_id))
#level 3 n
N_banners = length(unique(model_data$banner_id))
#level 4 n
N_regions = length(unique(model_data$region_id))

N_upc = length(unique(model_data$UPC))

#cluster ids
store_id = as.numeric(as.factor(model_data$store_id))
banner_id = as.numeric(as.factor(model_data$banner_id))
region_id = as.numeric(as.factor(model_data$region_id))
upc_id = as.numeric(as.factor(model_data$UPC))

## Create a vector of school IDs where j-th element gives school ID for class ID j
#upper_level_lookup <- unique(d[c("lower_id", "upper_id")])[,"upper_id"]
banner_level_lookup <- unique(model_data[c("store_id", "banner_id")])[,"banner_id"]
region_level_lookup <- unique(model_data[c("store_id", "region_id")])[,"region_id"]

#continuous outcome
Price = as.numeric(model_data$Price)
```

Consistent with Stan's best practices, we're going to dump the processed data into a separate file and clear our environment. Then, we'll read it back in.

```{r stan data dump}
stan_rdump(c("N_obs", "N_stores", "N_banners", "N_regions", "N_upc",
             "store_id", "banner_id", "region_id", "upc_id",
             "banner_level_lookup", "region_level_lookup",
             "Price"), file="data/stan_data_dump.R")

rm(banner_id); rm(banner_level_lookup); rm(N_banners); rm(N_obs); rm(N_regions);
rm(N_stores); rm(N_upc); rm(Price); rm(region_id); rm(store_id); rm(upc_id)
rm(model_data); rm(region_level_lookup)

data <- read_rdump("data/stan_data_dump.R") #import data
```

### Preview

We can see that the price, which is always positive, should be transformed. This makes sampling much faster. However, the log is highly skewed. A standization scaling works better. The scaling will be performed in Stan.

```{r}
qplot(data$Price)
qplot(log(data$Price))
qplot(scale(data$Price))
```


### Single level Model

Price as a function of UPC. With priors and generated quantities.

```{r}
writeLines(readLines("models/single_level.stan"))
```

Next, we'll compile the model. This allows us to check for errors.

```{r}
m1 <- stanc(file = "models/single_level.stan") # Check Stan file
m1 <- stan_model(stanc_ret = m1) # Compile Stan code
```

About 30 minutes execution time.

```{r}
fit1 <- sampling(m1, #use sampling function, rather than stan()
                warmup=1000, #recommended in Betancourt "RStan Workflow"
                iter=6000, #TOTAL iterations- first 1000 are warmup
                seed=1, #ensures reproducibility 
                data=data, 
                chains = 4, #each chain has different initial condition which helps to find pathological neighborhood of posterior
                cores = getOption("mc.cores", 1L),
                verbose = TRUE)
rm(m1)
```

```{r}
save.image(file="data/single_level.RData") 
```


#### Diagnostics

```{r}
list_of_draws <- rstan::extract(fit1)
print(names(list_of_draws))
print(fit1_upc, c("beta_0", "beta_1")) 
```

```{r}
fit1_loo <- loo(fit1)
fit1_loo
```

### Model Comparison (Save for when adding variables)

```{r}
fit3_upc_loo <- loo(fit3_upc)
# Compare log likelihoods
loo_compare(fit1_loo, fit2_loo, fit3_loo, fit1_upc_loo)
```

