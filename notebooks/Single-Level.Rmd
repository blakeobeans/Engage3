---
title: "Multi-level Pricing Model"
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = FALSE)
```

```{r, message = FALSE, warning = FALSE}
library(rstan)
library(loo)
library(tidyverse)
library(here)
setwd(here())
```

```{r}
rstan_options(auto_write = TRUE) #cache model
options(mc.cores = parallel::detectCores()) #multiple cores for multiple chains
```


We'll be doing some 2, 3 and even 4-level models in Stan, then comparing them using the Loo package.

### The Data


```{r}
#import remotely
model_data <- read.csv("data/model_data.csv")
```


```{r}
colnames(model_data) <- c("Price", "store_id", "UPC", "banner_id", "region_id")
```

The regressand is the price of an item. Regressors include the UPC of the item, the specific store, the supermarket brand, and the region.

```{r coding the data}
#level 1 n
N_obs = nrow(model_data)
#level 2 n
N_stores = length(unique(model_data$store_id))
#level 3 n
N_banners = length(unique(model_data$banner_id))
#level 4 n
N_regions = length(unique(model_data$region_id))

N_upc = length(unique(model_data$UPC))

#cluster ids
store_id = as.numeric(as.factor(model_data$store_id))
banner_id = as.numeric(as.factor(model_data$banner_id))
region_id = as.numeric(as.factor(model_data$region_id))
upc_id = as.numeric(as.factor(model_data$UPC))

## Create a vector of school IDs where j-th element gives school ID for class ID j
#upper_level_lookup <- unique(d[c("lower_id", "upper_id")])[,"upper_id"]
banner_level_lookup <- unique(model_data[c("store_id", "banner_id")])[,"banner_id"]
region_level_lookup <- unique(model_data[c("store_id", "region_id")])[,"region_id"]

#continuous outcome
Price = as.numeric(model_data$Price)
```

Consistent with Stan's best practices, we're going to dump the processed data into a separate file and clear our environment. Then, we'll read it back in.

```{r stan data dump}
stan_rdump(c("N_obs", "N_stores", "N_banners", "N_regions", "N_upc",
             "store_id", "banner_id", "region_id", "upc_id",
             "banner_level_lookup", "region_level_lookup",
             "Price"), file="data/stan_data_dump.R")

rm(banner_id); rm(banner_level_lookup); rm(N_banners); rm(N_obs); rm(N_regions);
rm(N_stores); rm(N_upc); rm(Price); rm(region_id); rm(store_id); rm(upc_id)
rm(model_data); rm(region_level_lookup)

data <- read_rdump("data/stan_data_dump.R") #import data
```

### Preview

We can see that the price, which is always positive, should be transformed. This makes sampling much faster. However, the log is highly skewed. A standization scaling works better. The scaling will be performed in Stan.

```{r}
qplot(data$Price)
qplot(log(data$Price))
qplot(scale(data$Price))
```


### Single level Model

Price as a function of UPC. With priors and generated quantities.

```{r}
writeLines(readLines("models/single level/single_level_no_gen.stan"))
```

Next, we'll compile the model. This allows us to check for errors.

```{r}
m1 <- stanc(file = "models/single level/single_level_no_gen.stan") # Check Stan file
m1 <- stan_model(stanc_ret = m1) # Compile Stan code
```

```{r}
fit1 <- sampling(m1, #use sampling function, rather than stan()
                warmup=1000, #
                iter=6000, #total iterations including warmup
                seed=1, #ensures reproducibility 
                data=data, 
                chains = 4, #each chain has different initial condition which helps to find pathological neighborhood of posterior
                cores = getOption("mc.cores", 1L),
                verbose = FALSE,
                refresh = 1000,
                control = list(max_treedepth = 15))
```

```{r}
rm(m1)
```

### Posterior Summary Statistics and Convergence Diagnostics

This is good summary information, but it's strange that they're bundled together. On the one hand, we want our parameter estimates, but on the other hand, we're curious about convergence. I can see why we want to know them all at once, but where you go with each of these is very difference: inference and model checking, respectively.

#### Summary Statistics

```{r}
list_of_draws <- rstan::extract(fit1)
print(names(list_of_draws))
round(summary(fit1, pars = 'sigma_e0')$summary, 2) #pars = NULL, probs=NULL
```

Converting to a matrix object to look at all samples.

```{r}
beta0_and_sigmae0 <- as.matrix(fit1, pars = c("beta_0", "sigma_e0"))
head(beta0_and_sigmae0)
```

```{r}
plot(fit1, pars = 'sigma_e0', ci_level = 0.95)
```


#### Sampler Diagnostics

```{r}
traceplot(fit1, pars = c("beta_0"), inc_warmup = FALSE)
```

```{r}
pairs(fit1, pars = c("beta_0", "sigma_e0"))
```

```{r}
sampler_params <- get_sampler_params(fit1, inc_warmup = TRUE)
sampler_params_chain1 <- sampler_params[[1]] #1 matrix per chain
colnames(sampler_params_chain1) #get names for all chains
```

Summary of sampler diagnostics.

```{r}
summary(do.call(rbind, sampler_params), digits = 2)
```

Individual chains

```{r}
lapply(sampler_params, summary, digits = 2)
```

To compare across chains. This works for any of the sampler parameters.

```{r}
mean_accept_stat_by_chain <- sapply(sampler_params, function(x) mean(x[, "accept_stat__"]))
print(mean_accept_stat_by_chain)
```

### Initial Values

```{r}
inits <- get_inits(fit1)
inits_chain1 <- inits[[1]]
print(inits_chain1)
```

### Warmup and Sampling Times

```{r}
print(get_elapsed_time(fit1))
```

### Sampling Diagnostics

```{r}
rstan::check_hmc_diagnostics(fit1) #does all 3 below
#rstan::check_divergences(fit1)
#rstan::check_energy(fit1)
#rstan::check_treedepth(fit1)
```

### Effective Samples and R-hat

```{r}
 fit1_summary <- summary(fit1)$summary %>% 
  as.data.frame() %>% 
  mutate(variable = rownames(.)) %>% 
  select(variable, everything()) %>% 
  as_data_frame()
```

#### Number of effective samples

```{r}
fit1_summary %>% 
  ggplot(aes(n_eff)) + 
  geom_histogram() + 
  xlim(0, 1000)
```

#### R-hat

```{r}
fit1_summary %>% 
  ggplot(aes(Rhat)) + 
  geom_histogram() + 
  geom_vline(aes(xintercept = 1.1), color = 'red')
```

### Posterior Predtive Analysis

Need generated quantities
